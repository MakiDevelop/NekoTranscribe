
//
//  ContentView.swift
//  NekoTranscribe
//
//  Created by åƒè‘‰ç‰§äºº on 2025/8/5.
//

import SwiftUI
import UniformTypeIdentifiers
import AppKit
import AVFoundation

@MainActor
struct ContentView: View {
    @StateObject private var audioProcessor = AudioProcessor()
    
    // MARK: - State Properties
    // @AppStorage("selectedLanguage") private var selectedLanguage: String = "zh-Hant"
    @AppStorage("selectedLanguage") private var selectedLanguage: String = "zh-Hant"
    
    @State private var draggedFileURL: URL?
    @State private var convertedFileURL: URL?
    @State private var transcript = ""
    @State private var showError = false
    @State private var errorMessage = ""
    @State private var audioPlayer: AVAudioPlayer?
    @State private var isPlaying = false
    
    // UI/UX State
    @State private var isDropTargeted = false
    @State private var didCopy = false

    // MARK: - Language Options
    private let availableLanguages = [
        "ç¹é«”ä¸­æ–‡": "zh-Hant",
        "ç®€ä½“ä¸­æ–‡": "zh-Hans",
        "English": "en",
        "Japanese": "ja",
        "Korean": "ko",
        "French": "fr",
        "German": "de",
        "å»£æ±è©±(ç²µèª)": "yue"
    ]

    // MARK: - Body
    var body: some View {
        ZStack {
            // Use a material background for a modern, adaptive look.
            Rectangle()
                .fill(.regularMaterial)
                .ignoresSafeArea()

            VStack(spacing: 20) {
                headerView
                languagePicker
                // splittingModeControls // æš«æ™‚éš±è—
                dropArea
                resultArea
            }
            .padding()
        }
        .onChange(of: audioProcessor.currentTranscript) { newValue in
            // ç•¶ AudioProcessor çš„ currentTranscript æ”¹è®Šæ™‚ï¼Œæ›´æ–°æœ¬åœ°çš„ transcript
            if !newValue.isEmpty {
                transcript = postProcessText(newValue)
            }
        }
        .frame(minWidth: 550, minHeight: 550)
        .alert("æç¤º", isPresented: $showError) {
            Button("ç¢ºå®š") { }
        } message: {
            Text(errorMessage)
        }
        .onDisappear(perform: stopAudio)
    }

    // MARK: - Subviews
    
    private var headerView: some View {
        HStack {
            Text("NekoTranscribe")
                .font(.largeTitle)
                .fontWeight(.bold)
            Spacer()
            Button(role: .destructive) {
                clearExportedAudio()
            } label: {
                Label("æ¸…é™¤æš«å­˜", systemImage: "trash")
            }
            .help("æ¸…é™¤æ‰€æœ‰å·²è½‰æ›çš„éŸ³è¨Šæª”")
        }
    }
    
    private var languagePicker: some View {
        Picker("éŸ³è¨Šèªè¨€ï¼š", selection: $selectedLanguage) {
            ForEach(availableLanguages.keys.sorted { $0 < $1 }, id: \.self) { key in
                Text(key).tag(availableLanguages[key]!)
            }
        }
        .pickerStyle(.segmented)
        .padding(.bottom, 5)
    }
    
    private var splittingModeControls: some View {
        VStack(alignment: .leading, spacing: 8) {
            Text("æ–·å¥æ¨¡å¼ï¼š")
                .font(.headline)
            
            Picker("æ–·å¥æ¨¡å¼", selection: $audioProcessor.splittingMode) {
                Text("èªéŸ³åˆ†æ®µï¼ˆæ¨è–¦ï¼‰").tag(AudioProcessor.SentenceSplittingMode.segmentBased)
                Text("èªç¾©æ–·å¥").tag(AudioProcessor.SentenceSplittingMode.semantic)
                Text("æ··åˆæ¨¡å¼").tag(AudioProcessor.SentenceSplittingMode.mixed)
            }
            .pickerStyle(.segmented)
            
            HStack {
                Toggle("åŒ…å«æ™‚é–“æˆ³", isOn: $audioProcessor.includeTimestamps)
                    .disabled(audioProcessor.splittingMode == .semantic)
                    .help(audioProcessor.splittingMode == .semantic ? "èªç¾©æ–·å¥æ¨¡å¼ä¸æ”¯æ´æ™‚é–“æˆ³" : "åœ¨é€å­—ç¨¿ä¸­é¡¯ç¤ºæ™‚é–“æˆ³")
                
                Spacer()
                
                // æ¸¬è©¦æŒ‰éˆ•çµ„
                HStack {
                    // æ‰‹å‹•åˆ·æ–°æŒ‰éˆ•ï¼ˆèª¿è©¦ç”¨ï¼‰
                    Button("ğŸ”„ åˆ·æ–°") {
                        print("ğŸ”¥ DEBUG: ç”¨æˆ¶é»æ“Šåˆ·æ–°æŒ‰éˆ•")
                        audioProcessor.forceRefreshFromCache()
                    }
                    .buttonStyle(.bordered)
                    .help("æ‰‹å‹•åˆ·æ–°è½‰éŒ„çµæœï¼ˆå¦‚æœè‡ªå‹•åˆ·æ–°å¤±æ•—ï¼‰")
                    
                    // åŸºæœ¬æ¸¬è©¦æŒ‰éˆ•
                    Button("ğŸ§ª æ¸¬è©¦") {
                        print("ğŸ”¥ DEBUG: æ¸¬è©¦æŒ‰éˆ•è¢«é»æ“Š")
                        print("ğŸ”¥ DEBUG: ç•¶å‰æ¨¡å¼: \(audioProcessor.splittingMode)")
                        print("ğŸ”¥ DEBUG: æ™‚é–“æˆ³: \(audioProcessor.includeTimestamps)")
                        print("ğŸ”¥ DEBUG: transcript é•·åº¦: \(transcript.count)")
                    }
                    .buttonStyle(.bordered)
                    .help("åŸºæœ¬èª¿è©¦ä¿¡æ¯")
                }
                
                Text(getModeDescription(audioProcessor.splittingMode))
                    .font(.caption)
                    .foregroundColor(.secondary)
            }
        }
        .padding(.horizontal, 4)
    }
    
    private func getModeDescription(_ mode: AudioProcessor.SentenceSplittingMode) -> String {
        switch mode {
        case .segmentBased:
            return "åŸºæ–¼èªéŸ³åœé “è‡ªç„¶åˆ†æ®µï¼Œæº–ç¢ºåº¦æœ€é«˜"
        case .semantic:
            return "åŸºæ–¼èªç¾©æ¨™è¨˜è©æ–·å¥ï¼Œé©åˆç„¡æ˜é¡¯åœé “çš„æ–‡å­—"
        case .mixed:
            return "çµåˆèªéŸ³åˆ†æ®µèˆ‡èªç¾©åˆ†æçš„æ··åˆæ¨¡å¼"
        }
    }
    
    private func getCurrentModeDisplay() -> String {
        let modeText: String
        switch audioProcessor.splittingMode {
        case .segmentBased:
            modeText = "èªéŸ³åˆ†æ®µ"
        case .semantic:
            modeText = "èªç¾©æ–·å¥"
        case .mixed:
            modeText = "æ··åˆæ¨¡å¼"
        }
        
        if audioProcessor.includeTimestamps && audioProcessor.splittingMode != .semantic {
            return "\(modeText) â€¢ å«æ™‚é–“æˆ³"
        } else {
            return modeText
        }
    }
    
    private var dropArea: some View {
        ZStack {
            RoundedRectangle(cornerRadius: 16)
                .fill(Color(nsColor: .controlBackgroundColor))
                .shadow(color: .black.opacity(0.1), radius: 5, x: 0, y: 2)

            RoundedRectangle(cornerRadius: 16)
                .strokeBorder(isDropTargeted ? Color.accentColor : Color(nsColor: .separatorColor), style: StrokeStyle(lineWidth: isDropTargeted ? 4 : 2, dash: [isDropTargeted ? 12 : 6]))
                .padding(4)

            VStack(spacing: 12) {
                Image(systemName: audioProcessor.isModelLoaded ? "arrow.down.doc.fill" : "hourglass")
                    .font(.system(size: 48))
                    .symbolEffect(.bounce, value: isDropTargeted)
                    .foregroundColor(isDropTargeted ? .accentColor : .secondary)
                
                Text(audioProcessor.isModelLoaded ? "æ‹–æ›³éŸ³è¨Šæˆ–å½±ç‰‡æª”æ¡ˆåˆ°æ­¤è™•" : "æ­£åœ¨è¼‰å…¥ AI æ¨¡å‹...")
                    .font(.headline)
                    .foregroundColor(.secondary)
            }
        }
        .frame(height: 200)
        .contentShape(Rectangle())
        .onDrop(of: [.fileURL], isTargeted: $isDropTargeted) { providers in
            guard audioProcessor.isModelLoaded else { return false }
            handleDrop(providers: providers)
            return true
        }
        .animation(.easeInOut, value: isDropTargeted)
    }
    
    private var resultArea: some View {
        VStack {
            if audioProcessor.isProcessing {
                processingView
            } else if !transcript.isEmpty {
                transcriptView
            } else if let url = draggedFileURL {
                fileInfo(for: url)
            } else {
                idlePromptView
            }
        }
        .frame(maxWidth: .infinity, minHeight: 150)
        .animation(.easeInOut, value: audioProcessor.isProcessing)
        .animation(.easeInOut, value: transcript)
    }
    
    private var idlePromptView: some View {
        VStack {
            Text("å®Œæˆæ‹–æ›³å¾Œï¼Œé€™è£¡æœƒé¡¯ç¤ºåˆ†æçµæœ")
                .font(.headline)
                .foregroundColor(.secondary)
        }
    }
    
    private func fileInfo(for url: URL) -> some View {
        VStack(alignment: .leading, spacing: 8) {
            Text("å·²é¸æ“‡æª”æ¡ˆï¼š")
                .font(.headline)
            Text(url.lastPathComponent)
                .font(.body)
                .foregroundColor(.secondary)
                .lineLimit(1)
                .help(url.path)
        }
    }
    
    private var processingView: some View {
        VStack(spacing: 15) {
            ProgressView() {
                Text(audioProcessor.processingStatus)
                    .font(.headline)
            }
            .progressViewStyle(.linear)
            
            // Show the partial transcript as it comes in
            if !transcript.isEmpty {
                ScrollView {
                    Text(transcript)
                        .font(.body)
                        .foregroundColor(.secondary)
                        .frame(maxWidth: .infinity, alignment: .leading)
                        .padding()
                }
                .background(Color(nsColor: .controlBackgroundColor))
                .cornerRadius(8)
            }
        }
    }
    
    private var transcriptView: some View {
        VStack(alignment: .leading, spacing: 10) {
            HStack {
                Text("é€å­—ç¨¿çµæœï¼š")
                    .font(.headline)
                
                // æš«æ™‚éš±è—æ¨¡å¼æŒ‡ç¤ºå™¨
                // Text(getCurrentModeDisplay())
                //     .font(.caption)
                //     .foregroundColor(.secondary)
                //     .padding(.horizontal, 8)
                //     .padding(.vertical, 2)
                //     .background(Color.accentColor.opacity(0.1))
                //     .cornerRadius(4)
                
                if let url = convertedFileURL {
                    Button {
                        if isPlaying { stopAudio() } else { playAudio(url: url) }
                    } label: {
                        Label(isPlaying ? "åœæ­¢" : "æ’­æ”¾", systemImage: isPlaying ? "stop.circle.fill" : "play.circle.fill")
                    }
                    .help("æ’­æ”¾è½‰æ›å¾Œçš„éŸ³è¨Š")
                }
                
                Spacer()
                
                Button {
                    copyToClipboard(transcript)
                } label: {
                    Label(didCopy ? "å·²è¤‡è£½!" : "è¤‡è£½", systemImage: didCopy ? "checkmark.circle.fill" : "doc.on.doc")
                }
                .help("è¤‡è£½é€å­—ç¨¿")
                .disabled(didCopy)
            }
            
            ScrollView {
                Text(transcript)
                    .font(.system(.body, design: .monospaced))
                    .lineSpacing(5)
                    .frame(maxWidth: .infinity, alignment: .leading)
                    .padding()
            }
            .background(Color(nsColor: .textBackgroundColor))
            .cornerRadius(8)
            .overlay(
                RoundedRectangle(cornerRadius: 8).stroke(Color(nsColor: .separatorColor), lineWidth: 1)
            )
        }
    }

    // MARK: - Functions
    
    private func handleDrop(providers: [NSItemProvider]) {
        guard let provider = providers.first else { return }
        
        provider.loadItem(forTypeIdentifier: UTType.fileURL.identifier, options: nil) { item, error in
            Task {
                if let error = error {
                    showError(message: "è¼‰å…¥æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š\(error.localizedDescription)")
                    return
                }
                
                guard let urlData = item as? Data, let url = URL(dataRepresentation: urlData, relativeTo: nil) else {
                    showError(message: "ç„¡æ³•è§£ææª”æ¡ˆ URL")
                    return
                }
                
                if !audioProcessor.isSupportedFile(url) {
                    showError(message: "ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ã€‚")
                    return
                }
                
                self.draggedFileURL = url
                self.convertedFileURL = nil
                self.transcript = ""
                self.stopAudio()
                
                audioProcessor.convertToWhisperFormat(inputURL: url) { result in
                    Task {
                        switch result {
                        case .success(let outputURL):
                            self.convertedFileURL = outputURL
                            transcribe(audioURL: outputURL)
                        case .failure(let error):
                            showError(message: "è½‰æ›å¤±æ•—ï¼š\(error.localizedDescription)")
                        }
                    }
                }
            }
        }
    }
    
    private func transcribe(audioURL: URL) {
        let whisperLanguageCode = selectedLanguage.starts(with: "zh") ? "zh" : selectedLanguage
        
        let onProgress: (String) -> Void = { progressText in
            DispatchQueue.main.async {
                self.transcript = self.postProcessText(progressText)
            }
        }
        
        let onCompletion: (Result<String, Error>) -> Void = { result in
            DispatchQueue.main.async {
                switch result {
                case .success(let finalText):
                    self.transcript = self.postProcessText(finalText)
                case .failure(let error):
                    showError(message: "åˆ†æå¤±æ•—ï¼š\(error.localizedDescription)")
                }
            }
        }
        
        audioProcessor.transcribeAudio(url: audioURL, language: whisperLanguageCode, onProgress: onProgress, onCompletion: onCompletion)
    }
    
    private func postProcessText(_ text: String) -> String {
        if self.selectedLanguage == "zh-Hant" {
            return text.applyingTransform(StringTransform(rawValue: "Any-Hant"), reverse: false) ?? text
        } else {
            return text
        }
    }
    
    private func showError(message: String) {
        errorMessage = message
        showError = true
    }
    
    private func openDocumentsFolder() {
        guard let documentsURL = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first else { return }
        NSWorkspace.shared.open(documentsURL)
    }
    
    private func clearExportedAudio() {
        audioProcessor.deleteAllExportedAudio { result in
            DispatchQueue.main.async {
                switch result {
                case .success(let count):
                    showError(message: "å·²æ¸…é™¤ \(count) å€‹å·²è½‰æ›çš„éŸ³è¨Šæª”æ¡ˆ")
                    self.draggedFileURL = nil
                    self.convertedFileURL = nil
                    self.transcript = ""
                case .failure(let error):
                    showError(message: "åˆªé™¤å¤±æ•—ï¼š\(error.localizedDescription)")
                }
            }
        }
    }
    
    private func copyToClipboard(_ text: String) {
        let pasteboard = NSPasteboard.general
        pasteboard.clearContents()
        pasteboard.setString(text, forType: .string)
        didCopy = true
        // Reset the button state after 2 seconds
        Task {
            try? await Task.sleep(for: .seconds(2))
            didCopy = false
        }
    }
    
    // MARK: - Audio Player
    
    private func playAudio(url: URL) {
        guard FileManager.default.fileExists(atPath: url.path) else {
            showError(message: "éŸ³è¨Šæª”æ¡ˆä¸å­˜åœ¨")
            return
        }
        
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.play()
            isPlaying = true
        } catch {
            showError(message: "æ’­æ”¾éŸ³è¨Šå¤±æ•—ï¼š\(error.localizedDescription)")
        }
    }
    
    private func stopAudio() {
        audioPlayer?.stop()
        audioPlayer = nil
        isPlaying = false
    }
}

#Preview {
    ContentView()
}
